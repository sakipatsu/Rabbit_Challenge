{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "3_1_simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakipatsu/Rabbit_Challenge/blob/main/3_1_simple_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a938dd-b421-4874-e492-950de2d67698"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59"
      },
      "source": [
        "import sys\n",
        "# sys.path.append('/content/drive/My Drive/DNN_code')\n",
        "sys.path.append('/content/drive/My Drive/StudyAI/Step4')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feXB1SiLP4OL"
      },
      "source": [
        "# simple RNN\n",
        "### バイナリ加算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tzSWNYwxP4OM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1975c820-05bb-4e71-fe04-ce5f82bf3488"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:0.6824881499345677\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "105 + 27 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0330159266858356\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "97 + 37 = 223\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.010369827001051\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "108 + 92 = 145\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0972158830608454\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "94 + 4 = 255\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.036290633070051\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[0 0 0 0 1 1 1 1]\n",
            "9 + 6 = 253\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.8525475074115362\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "48 + 46 = 255\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9337263179191776\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "103 + 68 = 255\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0006683074000102\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "91 + 114 = 5\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.2063562881953716\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "36 + 96 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0538111283834408\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "61 + 86 = 64\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0277341233783794\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "61 + 91 = 1\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.8844876246882708\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "9 + 72 = 208\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.7714687877105045\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "70 + 88 = 254\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9519074542686047\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "88 + 79 = 255\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.9079994541632479\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "41 + 105 = 80\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.9667394142400818\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "67 + 9 = 90\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.1066668011354335\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "15 + 87 = 255\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.9459681925310489\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "42 + 29 = 127\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.1573405415425757\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "103 + 51 = 117\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.0449984541138098\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "93 + 3 = 92\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.2931356274284098\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "55 + 77 = 250\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.6706017899704659\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "65 + 110 = 175\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.005059697390002\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "47 + 63 = 120\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.8938344620315821\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "85 + 99 = 190\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.7043528444116763\n",
            "Pred:[1 1 1 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "16 + 123 = 235\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.6303426271810364\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "23 + 96 = 127\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.7779470321967099\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "38 + 102 = 8\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.3705926556590477\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "118 + 72 = 254\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.5382587265595484\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "76 + 111 = 179\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.5543390992565194\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "69 + 52 = 123\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.2882325065250949\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "24 + 74 = 98\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.6880482666287632\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "108 + 31 = 131\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.48265351610954615\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "52 + 6 = 10\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.6365954596606589\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "83 + 107 = 188\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.16814062139155492\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "18 + 91 = 109\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.9490419678836284\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "24 + 108 = 116\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.2118828683210126\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "11 + 65 = 76\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.37743550647139884\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "30 + 56 = 70\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.719101923356157\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "93 + 40 = 245\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.14896054684771567\n",
            "Pred:[0 0 0 1 1 1 1 0]\n",
            "True:[0 0 0 1 1 1 1 0]\n",
            "2 + 28 = 30\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.46978231353290895\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "47 + 18 = 81\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.1387944129419313\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "22 + 82 = 104\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.2681801514652768\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "75 + 38 = 117\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.18975643517560845\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "70 + 23 = 93\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.4983601001262815\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "72 + 59 = 179\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.02698414911208089\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "88 + 0 = 88\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.10590309283314023\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "30 + 93 = 123\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.2078023671078492\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "126 + 12 = 138\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.09255290625005251\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "53 + 57 = 110\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.03844502718053903\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "49 + 18 = 67\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.15537947921139988\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "28 + 40 = 68\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.026650516205531858\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "112 + 42 = 154\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.07459773575031527\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "99 + 116 = 215\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.02052488570255189\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "73 + 117 = 190\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.05234984793606051\n",
            "Pred:[1 1 0 1 1 0 0 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "102 + 115 = 217\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.013962260795571805\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "36 + 80 = 116\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.012315157691555128\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "41 + 73 = 114\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.13586119162801427\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "93 + 115 = 208\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.0212738002196437\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "64 + 31 = 95\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.0564344808590087\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "88 + 114 = 202\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.05873891639385622\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "87 + 62 = 149\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.01287838083856659\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "18 + 19 = 37\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.004883174368417397\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "101 + 85 = 186\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.03447423194820878\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "127 + 3 = 130\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.033841765953631246\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "13 + 122 = 135\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.03034314304433469\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "112 + 109 = 221\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.029520173865862327\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "50 + 113 = 163\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.03245591085410764\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "101 + 15 = 116\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.03444949873808325\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "47 + 125 = 172\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.00387676307272193\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "105 + 40 = 145\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.010794728386897176\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "93 + 86 = 179\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.02100410937718841\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "15 + 43 = 58\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.023763128718570673\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "70 + 58 = 128\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.007542952572633652\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "88 + 102 = 190\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.013029203729288272\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "126 + 18 = 144\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.006496441620484013\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "10 + 80 = 90\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.006004845923351768\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "36 + 37 = 73\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.01693229757635974\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "2 + 63 = 65\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.003613535876156464\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "45 + 66 = 111\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.007814309878973805\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "15 + 94 = 109\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.00302222610261313\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "113 + 76 = 189\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.008501478347128963\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "105 + 27 = 132\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.0072198943974925755\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "34 + 69 = 103\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.007368257343526518\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "96 + 127 = 223\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.006765004838526206\n",
            "Pred:[1 1 0 1 1 1 0 0]\n",
            "True:[1 1 0 1 1 1 0 0]\n",
            "119 + 101 = 220\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.004349422857857379\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "92 + 34 = 126\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.009908132327899742\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "108 + 119 = 227\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.004843475663332792\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "25 + 43 = 68\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.00722183487561216\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "31 + 104 = 135\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0012704298210627913\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "53 + 97 = 150\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0059609348316149524\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "122 + 88 = 210\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.004320518321464229\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "74 + 88 = 162\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.006085174752064784\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "115 + 84 = 199\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.003858147193772517\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "36 + 87 = 123\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.009990189753974251\n",
            "Pred:[1 1 1 0 0 1 0 0]\n",
            "True:[1 1 1 0 0 1 0 0]\n",
            "103 + 125 = 228\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0035308070135150393\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "35 + 6 = 41\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0024556298088985093\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "103 + 6 = 109\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0014020100554675246\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "77 + 68 = 145\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.004660435073862522\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "116 + 44 = 160\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0018143474025632824\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "65 + 86 = 151\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7zQEPrtP4OP"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n",
        "\n",
        "\n",
        "## [try] 重みの初期化方法を変更してみよう\n",
        "Xavier, He\n",
        "\n",
        "## [try] 中間層の活性化関数を変更してみよう\n",
        "ReLU(勾配爆発を確認しよう)<br>\n",
        "tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    }
  ]
}